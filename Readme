Here is the explanatory material for paper'Generative Models Improve Radiomics Reproducibility in Low Dose CTs: A Simulation Study'

Three generative models --Encoder-decoder network, Conditional Generative Adversarial Networks(CGAN), Cycle GAN-- were selected as test models. This part of content
focus on executing project. The flowchart of executing code of this project was show as follow.

You can find source codes of CGAN and the link of pretrained models in this branch.

As you can see, there are three code files in our CGAN model --Addnoiseinradiomic.m,convertdicomtopng.py and pix2pix.py.

Addnoiseradiomic.m is the source code for MATLAB, you can find more details how to use this part of source code based on the
annotates in codes.

As we mentioned in our paper, the input images of our models are PNG orJPG images and the output images of our models are DICOM for better Radiomic calculation. Therefore, we need convert DICOM files to PNG/JPG files at first, you can use convertdicompng.py to finish this step. 

You can find one pre-trained CGAN (100 Epochs) at this link: https://www.amazon.de/clouddrive/share/3eiaXEQwr0jTwt7uNFOnhuWwb2YmUe5FA7nG8PDxyb6?_encoding=UTF8&%2AVersion%2A=1&%2Aentries%2A=0&mgh=1

The specific procedure of using our trained CGAN are shown as follow:

1.Copy Dicom files(one patient) to  ’./Data/Dicom/’
2.Running ‘convenrtdicomtopng.py’, code will convert DICOM files to jpg file and store in ‘./Data/val/’
3.Running ‘pix2pix.py’,code will output result in ‘./Data/Result/’, there are two kind of outputs, one type is jpg images which store in ‘./Data/Result/images’, the another type is DICOM images, which store in ‘./Data/Result/dicomimages’

Due to limited space of our amazon online drive, there are only one trained CGAN models is available at this moment. You can find more about more pre-trained model at here.

The pre-trained model can be ran by using PC, it took 0.8s to process one image (by using a Core i7 8565 U CPU)